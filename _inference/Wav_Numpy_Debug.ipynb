{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i)['index'], p.get_device_info_by_index(i)['name'])\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 4\n",
    "RATE = 48000\n",
    "WAVE_OUTPUT_FILENAME_PREFIX = \"./hybrid/jw_test\"\n",
    "MAX_RECORDINGS = 5\n",
    "RECORDING_DURATION = 10  # in seconds\n",
    "INPUT_DEVICE_INDEX = 1\n",
    "\n",
    "def record_and_save_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=INPUT_DEVICE_INDEX)\n",
    "\n",
    "    frames = []\n",
    "    numpy_data = []\n",
    "    segment_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            \n",
    "            int_data = np.frombuffer(data, dtype=np.int16)\n",
    "            float_data = int_data.astype(np.float32) / 32767.0 # convert to float\n",
    "            reshaped_data = float_data.reshape(-1, CHANNELS)\n",
    "\n",
    "            # # Convert the audio chunk into a NumPy array\n",
    "            # audio_data = np.frombuffer(data, dtype=np.int16).reshape(CHANNELS, -1)\n",
    "            frames.append(data)\n",
    "            print(reshaped_data.shape)\n",
    "\n",
    "            segment_count += 1\n",
    "\n",
    "            # Save the current audio segment every 10 seconds\n",
    "            if segment_count % (RATE * RECORDING_DURATION) == 0:\n",
    "                index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "                waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "                waveFile.setnchannels(CHANNELS)\n",
    "                waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                waveFile.setframerate(RATE)\n",
    "                # # # Convert the NumPy array to bytes\n",
    "                # audio_bytes = frames.astype(np.int16).tobytes()\n",
    "\n",
    "                waveFile.writeframes(b''.join(frames))\n",
    "                # waveFile.writeframes(b''.join(audio_bytes))\n",
    "                waveFile.close()\n",
    "\n",
    "                frames = []\n",
    "\n",
    "            # If the recording exceeds 10 seconds, reset the count\n",
    "            if segment_count // (RATE * RECORDING_DURATION) >= MAX_RECORDINGS:\n",
    "                segment_count = 0\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Streaming stopped by user\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "    finally:\n",
    "        # Save the last audio segment before exiting\n",
    "        index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "record_and_save_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 4\n",
    "RATE = 48000\n",
    "WAVE_OUTPUT_FILENAME_PREFIX = \"./hybrid/working_\"\n",
    "MAX_RECORDINGS = 10\n",
    "RECORDING_DURATION = 10  # in seconds\n",
    "INPUT_DEVICE_INDEX = 1\n",
    "\n",
    "def record_and_save_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=INPUT_DEVICE_INDEX)\n",
    "\n",
    "    frames = []\n",
    "    segment_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            # # Convert the audio chunk into a NumPy array\n",
    "            # audio_data = np.frombuffer(data, dtype=np.int16).reshape(CHANNELS, -1)\n",
    "            frames.append(data)\n",
    "\n",
    "            segment_count += 1\n",
    "\n",
    "            # Save the current audio segment every 10 seconds\n",
    "            if segment_count % (RATE * RECORDING_DURATION) == 0:\n",
    "                index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "                waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "                waveFile.setnchannels(CHANNELS)\n",
    "                waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                waveFile.setframerate(RATE)\n",
    "                # # # Convert the NumPy array to bytes\n",
    "                # audio_bytes = frames.astype(np.int16).tobytes()\n",
    "\n",
    "                waveFile.writeframes(b''.join(frames))\n",
    "                # waveFile.writeframes(b''.join(audio_bytes))\n",
    "                waveFile.close()\n",
    "\n",
    "                frames = []\n",
    "\n",
    "            # If the recording exceeds 10 seconds, reset the count\n",
    "            if segment_count // (RATE * RECORDING_DURATION) >= MAX_RECORDINGS:\n",
    "                segment_count = 0\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Streaming stopped by user\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "    finally:\n",
    "        # Save the last audio segment before exiting\n",
    "        index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "record_and_save_audio()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording 500ms only to Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 500\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 4\n",
    "RATE = 48000\n",
    "WAVE_OUTPUT_FILENAME_PREFIX = \"./hybrid/working_nofinally_TEST\"\n",
    "MAX_RECORDINGS = 96\n",
    "RECORDING_DURATION = 10  # in seconds\n",
    "INPUT_DEVICE_INDEX = 1\n",
    "\n",
    "def record_and_save_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=INPUT_DEVICE_INDEX)\n",
    "\n",
    "    frames = []\n",
    "    segment_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            # # Convert the audio chunk into a NumPy array\n",
    "            # audio_data = np.frombuffer(data, dtype=np.int16).reshape(CHANNELS, -1)\n",
    "            frames.append(data)\n",
    "\n",
    "          \n",
    "            waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX  + '.wav', 'wb')\n",
    "            waveFile.setnchannels(CHANNELS)\n",
    "            waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            waveFile.setframerate(RATE)\n",
    "            # # # Convert the NumPy array to bytes\n",
    "            # audio_bytes = frames.astype(np.int16).tobytes()\n",
    "\n",
    "            waveFile.writeframes(b''.join(frames))\n",
    "            # waveFile.writeframes(b''.join(audio_bytes))\n",
    "            waveFile.close()\n",
    "\n",
    "            if len(frames) == MAX_RECORDINGS:\n",
    "               frames = []\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Streaming stopped by user\")\n",
    "\n",
    "   \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "record_and_save_audio()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recording 500ms to wav alternatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 500\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 4\n",
    "RATE = 48000\n",
    "WAVE_OUTPUT_FILENAME_PREFIX = \"./hybrid/working_dog_1s\"\n",
    "MAX_RECORDINGS = 96\n",
    "RECORDING_DURATION = 10  # in seconds\n",
    "INPUT_DEVICE_INDEX = 1\n",
    "\n",
    "def record_and_save_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=INPUT_DEVICE_INDEX)\n",
    "\n",
    "    frames = []\n",
    "    segment_count = 0\n",
    "\n",
    "    try:\n",
    "\n",
    "        while True:\n",
    "            if segment_count == 20:\n",
    "                break\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "            \n",
    "            index_no = segment_count% 10\n",
    "            \n",
    "            waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX  + str(index_no) + '.wav', 'wb')\n",
    "            waveFile.setnchannels(CHANNELS)\n",
    "            waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            waveFile.setframerate(RATE)\n",
    "\n",
    "            waveFile.writeframes(b''.join(frames))\n",
    "            # waveFile.writeframes(b''.join(audio_bytes))\n",
    "            waveFile.close()\n",
    "            \n",
    "            if len(frames) == MAX_RECORDINGS:\n",
    "                segment_count +=1\n",
    "                # time.sleep(0.05)\n",
    "                frames = []\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Streaming stopped by user\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "record_and_save_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 4\n",
    "RATE = 48000\n",
    "WAVE_OUTPUT_FILENAME_PREFIX = \"./hybrid/working_buffertobytes\"\n",
    "MAX_RECORDINGS = 10\n",
    "RECORDING_DURATION = 10  # in seconds\n",
    "INPUT_DEVICE_INDEX = 1\n",
    "\n",
    "def record_and_save_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK,\n",
    "                        input_device_index=INPUT_DEVICE_INDEX)\n",
    "\n",
    "    frames = []\n",
    "    segment_count = 0\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            # # Convert the audio chunk into a NumPy array\n",
    "            audio_data = np.frombuffer(data, dtype=np.int16).reshape(CHANNELS, -1)\n",
    "            frames.append(audio_data)\n",
    "\n",
    "            segment_count += 1\n",
    "\n",
    "            # Save the current audio segment every 10 seconds\n",
    "            if segment_count % (RATE * RECORDING_DURATION) == 0:\n",
    "                index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "                waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "                waveFile.setnchannels(CHANNELS)\n",
    "                waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                waveFile.setframerate(RATE)\n",
    "                #  # Convert the NumPy array to bytes\n",
    "                audio_bytes = frames.tobytes()\n",
    "                \n",
    "                waveFile.writeframes(b''.join(frames))\n",
    "                # waveFile.writeframes(b''.join(audio_bytes))\n",
    "                waveFile.close()\n",
    "\n",
    "                frames = []\n",
    "\n",
    "            # If the recording exceeds 10 seconds, reset the count\n",
    "            if segment_count // (RATE * RECORDING_DURATION) >= MAX_RECORDINGS:\n",
    "                segment_count = 0\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Streaming stopped by user\")\n",
    "\n",
    "    finally:\n",
    "        # Save the last audio segment before exiting\n",
    "        index = (segment_count // (RATE * RECORDING_DURATION)) % MAX_RECORDINGS\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME_PREFIX + str(index) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "record_and_save_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference_model import *\n",
    "from util_funcs import * \n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import os \n",
    "import wave\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from extract_salsalite import extract_features\n",
    "from datetime import datetime\n",
    "import pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Global model settings, put into configs / .yml file eventually\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "resnet_style = 'bottleneck'\n",
    "n_classes = 4\n",
    "active_classes = ['dog' , 'impact' , 'speech', 'noise']\n",
    "fs = 48000\n",
    "trained_model_filepath = \"./saved_models/remove_silence_wgn_random_all_aug.h5\"\n",
    "\n",
    "\"\"\"Create the salsa-lite model class to load the weights into\"\"\"\n",
    "# For JW testing\n",
    "window_duration_s = 0.5\n",
    "feature_len = int(window_duration_s * 10 * 16 + 1) # General FFT formula\n",
    "\n",
    "input_shape = (95, feature_len, 7) # Height, Width , Channels shape\n",
    "print(\"Input shape : \", input_shape)\n",
    "# Get the salsa-lite model\n",
    "salsa_lite_model = get_model(input_shape    = input_shape, \n",
    "                             resnet_style   = resnet_style, \n",
    "                             n_classes      = n_classes,\n",
    "                             azi_only       = True,\n",
    "                             batch_size     = 1)\n",
    "\n",
    "\"\"\"Load the tflite model\"\"\"\n",
    "with open(r'D:\\DEHE\\_salsa_tensorflow\\_inference\\saved_models\\remove_silence_wgn_random_all_aug\\remove_silence_wgn_random_all_aug\\tflite_model.tflite', 'rb') as fid:\n",
    "    tflite_model = fid.read()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\"\"\"Implement streaming into audio reading here\"\"\"\n",
    "channels = 4  # Number of audio channels\n",
    "device_index = 1  # Input device index (change to the desired input device)\n",
    "chunk_size = 500 # Number of frames per chunk\n",
    "buffer_size = 48 # Number of chunks to accumulate in the buffer\n",
    "\n",
    "# Initialize PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Open the audio input stream with the specified number of channels\n",
    "stream = audio.open(\n",
    "    format=pyaudio.paInt16,  # 16-bit PCM format\n",
    "    channels=channels,  # Set to 4 channels\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    input_device_index=device_index,\n",
    "    frames_per_buffer=chunk_size\n",
    ")\n",
    "\n",
    "print(\"Streaming audio...\")\n",
    "\n",
    "# Initialize a buffer to accumulate audio data\n",
    "audio_buffer = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read a chunk of audio data from the stream\n",
    "        audio_chunk = stream.read(chunk_size)\n",
    "\n",
    "        # Convert the audio chunk into a NumPy array\n",
    "        audio_data = np.frombuffer(audio_chunk, dtype=np.int16).reshape(channels, -1)\n",
    "        \n",
    "\n",
    "        # Append the chunk to the buffer\n",
    "        audio_buffer.append(audio_data)\n",
    "\n",
    "        # If the buffer is full, process its contents\n",
    "        if len(audio_buffer) == buffer_size:\n",
    "            # Stack the chunks in the buffer to create a larger data array\n",
    "            audio_buffer = np.concatenate(audio_buffer, axis=1)\n",
    "\n",
    "            # # Create a WAV file object\n",
    "            # wave_file = wave.open(\"recorded_audio_500ms.wav\", \"wb\")\n",
    "            # wave_file.setnchannels(channels)\n",
    "            # wave_file.setsampwidth(2)  # 2 bytes per sample for 16-bit audio\n",
    "            # wave_file.setframerate(fs)\n",
    "\n",
    "            # # Convert the NumPy array to bytes\n",
    "            # audio_bytes = audio_data.tobytes()\n",
    "\n",
    "            # # Write the audio data to the WAV file\n",
    "            # wave_file.writeframes(audio_bytes)\n",
    "\n",
    "            # # Close the WAV file\n",
    "            # wave_file.close()\n",
    "            \n",
    "            \n",
    "            \n",
    "            feature = extract_features(audio_buffer)\n",
    "            feature = np.expand_dims(feature, axis = 0)\n",
    "            feature = np.transpose(feature, [0, 3, 2, 1])\n",
    "\n",
    "            # TFLite prediction\n",
    "            interpreter.set_tensor(input_details[0]['index'], feature)\n",
    "            interpreter.invoke()\n",
    "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "            \n",
    "            # Process output of prediction\n",
    "            sed_pred = remove_batch_dim(np.array(output_data[:, :, :n_classes]))\n",
    "            sed_pred = apply_sigmoid(sed_pred)\n",
    "            sed_pred = (sed_pred > 0.5).astype(int)  \n",
    "            azi_pred = convert_xy_to_azimuth(remove_batch_dim(np.array(output_data[:, : , n_classes:])))\n",
    "            frame_outputs = []\n",
    "            for i in range(len(sed_pred)):\n",
    "                final_azi_pred = sed_pred[i] * azi_pred[i]\n",
    "                if int(sed_pred[i][-1]) == 1:\n",
    "                    final_azi_pred[-1] = 0\n",
    "                output = np.concatenate([sed_pred[i], final_azi_pred], axis=-1)\n",
    "                # print(output)\n",
    "                frame_outputs.append(output.flatten())\n",
    "            \n",
    "            # Anything beyond this point is just my formating for the output data for personal testing\n",
    "            # replace as per demo requirements\n",
    "            frame_outputs = np.array(frame_outputs)\n",
    "            averaged_output = np.mean(frame_outputs, axis=0)\n",
    "            any_class = 0\n",
    "            out_string = \"\"\n",
    "            for j in range(3):\n",
    "                if averaged_output[j] > 0.5:\n",
    "                    out_string += \"{} : {}, \".format(active_classes[j], averaged_output[j+n_classes])\n",
    "                    any_class += 1\n",
    "            if any_class == 0:\n",
    "                print(\"No class present\")\n",
    "            else:\n",
    "                print(\"Class    |   Average Azimuth\")\n",
    "                print(out_string)\n",
    "                \n",
    "            # Clear the buffer\n",
    "            audio_buffer = []\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Streaming stopped by user\")\n",
    "    \n",
    "    \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-lite-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
