{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf \n",
    "import librosa\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting Audio Files\n",
    "\n",
    "Core files are separated into Dog , Speech , Impact\n",
    "\n",
    "Segment into 200ms chunks with 100ms overlap \n",
    "\n",
    "Saved in \"class_azimuth_idx.wav\" file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5983/5983 [00:17<00:00, 346.39it/s]\n",
      "100%|██████████| 5983/5983 [00:18<00:00, 329.76it/s]\n",
      "100%|██████████| 5983/5983 [00:18<00:00, 329.19it/s]\n",
      "100%|██████████| 5983/5983 [00:17<00:00, 333.01it/s]\n",
      "100%|██████████| 5983/5983 [00:26<00:00, 225.76it/s]\n",
      "100%|██████████| 5983/5983 [00:40<00:00, 145.95it/s]\n",
      "100%|██████████| 6679/6679 [00:45<00:00, 145.54it/s]\n",
      "100%|██████████| 6679/6679 [00:49<00:00, 134.47it/s]\n",
      "100%|██████████| 6679/6679 [00:45<00:00, 145.48it/s]\n",
      "100%|██████████| 6679/6679 [00:45<00:00, 147.08it/s]\n",
      "100%|██████████| 6679/6679 [00:46<00:00, 143.40it/s]\n",
      "100%|██████████| 6679/6679 [00:47<00:00, 141.08it/s]\n",
      "100%|██████████| 6013/6013 [00:45<00:00, 133.42it/s]\n",
      "100%|██████████| 6013/6013 [00:45<00:00, 131.49it/s]\n",
      "100%|██████████| 6013/6013 [00:44<00:00, 134.71it/s]\n",
      "100%|██████████| 6013/6013 [00:44<00:00, 133.75it/s]\n",
      "100%|██████████| 6013/6013 [00:44<00:00, 136.10it/s]\n",
      "100%|██████████| 6013/6013 [00:44<00:00, 134.34it/s]\n"
     ]
    }
   ],
   "source": [
    "class_types = ['Dog', 'Impact' , 'Speech']\n",
    "for ct in class_types:\n",
    "    \n",
    "    # raw data directory\n",
    "    full_data_dir = '../dataset/data/Dataset_concatenated_tracks/{}/'.format(ct)\n",
    "    # cleaned, output data directory\n",
    "    output_data_dir = '../dataset/cleaned_data_noise/{}'.format(ct.lower())\n",
    "    \n",
    "    # create dirs\n",
    "    os.makedirs(output_data_dir, exist_ok=True)\n",
    "    \n",
    "    # Manual settings \n",
    "    fs=48000\n",
    "    frame_len = int(0.2*fs) # 200ms\n",
    "    hop_len = int(0.1*fs)   # 100ms\n",
    "    \n",
    "    # loop through raw data dir\n",
    "    for file in os.listdir(full_data_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            fullfn = os.path.join(full_data_dir, file)\n",
    "            \n",
    "            # extract azimuth from gt\n",
    "            vars = file.split('_')\n",
    "            azimuth = vars[2]\n",
    "            \n",
    "            # load audio\n",
    "            audio , _ = librosa.load(fullfn, sr=fs, mono=False, dtype=np.float32)\n",
    "            \n",
    "            signal_power = np.mean(np.abs(audio) ** 2)\n",
    "            desired_SNR_dB = 20\n",
    "            # Calculate the standard deviation of the noise\n",
    "            noise_std_dev = np.sqrt(signal_power / (10 ** (desired_SNR_dB / 10)))\n",
    "            # Generate the noise\n",
    "            noise = np.random.normal(0, noise_std_dev, size=audio.shape)\n",
    "            audio += noise\n",
    "            \n",
    "            # Segment the audio input into overlapping frames\n",
    "            frames = librosa.util.frame(audio, frame_length=frame_len, hop_length=hop_len)\n",
    "            \n",
    "            # Transpose into (n_segments, timebins, channels)\n",
    "            frames = frames.T\n",
    "            for idx, frame in enumerate(tqdm(frames)):\n",
    "                final_fn = \"{}_{}_{}.wav\".format(ct.lower(), azimuth, idx+1)\n",
    "                final_fp = os.path.join(output_data_dir, final_fn)\n",
    "                sf.write(final_fp, frame, samplerate=48000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking SALSA-Lite feature dimensions/parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmax_doa = 2000\n",
    "n_fft = 1024\n",
    "fmin_doa = 50 \n",
    "fs = 48000\n",
    "fmax_doa = np.min((fmax_doa, fs // 2))\n",
    "n_bins = n_fft // 2 + 1\n",
    "lower_bin = int(np.floor(fmin_doa * n_fft / float(fs)))  # 512: 1; 256: 0\n",
    "upper_bin = int(np.floor(fmax_doa * n_fft / float(fs)))  # 9000Hz: 512: 192, 256: 96\n",
    "lower_bin = np.max((1, lower_bin))\n",
    "\n",
    "print(fmax_doa, fmin_doa, upper_bin, lower_bin)\n",
    "\n",
    "fmax = 9000  # Hz\n",
    "cutoff_bin = int(np.floor(fmax * n_fft / float(fs)))\n",
    "print(cutoff_bin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
