{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from augmented_dataset_generator import full_feature_with_norm\n",
    "import yaml\n",
    "import soundfile as sf\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions to create features, and choose which frames to replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_scaling(x):\n",
    "    \"\"\"Scaling an array to fit between -1 and 1\"\"\"\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    x_normed = (x - x_min) / (x_max - x_min)\n",
    "    x_scaled = 2 * x_normed - 1\n",
    "    \n",
    "    return x_scaled\n",
    "\n",
    "def extract_features(audio_data,\n",
    "                     cfg = None,\n",
    "                     data_config: str = './configs/salsa_lite_demo_3class.yml'\n",
    "                    ) -> None:\n",
    "    \"\"\"\n",
    "    Extract SALSA-Lite features from a segment of audio \n",
    "    SALSA-Lite consists of:\n",
    "        - 4 Log-linear spectrograms \n",
    "        - 3 Normalized Interchannel Phase Differences \n",
    "\n",
    "    [This needs to be revised for the demo]\n",
    "    The frequency range of log-linear spectrogram is 0 to 9kHz.\n",
    "\n",
    "    Arguments\n",
    "    -----------\n",
    "    audio_data (np.ndarray) : audio data from mic streaming (assuming it is 4 channels)\n",
    "    cfg (array)             : array of configuration parameters (from .yml file)\n",
    "    data_config (.yml file) : filepath to the .yml config file used for SALSA-Lite\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    None \n",
    "\n",
    "    To-do\n",
    "    ------\n",
    "    \"\"\"\n",
    "    if cfg is None:\n",
    "        # Load data config files\n",
    "        with open(data_config, 'r') as stream:\n",
    "            try:\n",
    "                cfg = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "    # Parse config file\n",
    "    fs = cfg['data']['fs']\n",
    "    n_fft = cfg['data']['n_fft']\n",
    "    hop_length = cfg['data']['hop_len']\n",
    "    win_length = cfg['data']['win_len']\n",
    "\n",
    "    # Doa info\n",
    "    n_mics = 4\n",
    "    fmin_doa = cfg['data']['fmin_doa']\n",
    "    fmax_doa = cfg['data']['fmax_doa']\n",
    "    \n",
    "    \"\"\"\n",
    "    For the demo, fmax_doa = 4kHz, fs = 48kHz, n_fft = 512, hop = 300\n",
    "    This results in the following:\n",
    "        n_bins      = 257\n",
    "        lower_bin   = 1\n",
    "        upper_bin   = 42\n",
    "        cutoff_bin  = 96 \n",
    "        logspecs -> 95 bins total\n",
    "        phasespecs -> 41 bins total\n",
    "        \n",
    "    Since these are all fixed, can we just put them into the config.yml instead\n",
    "    and just read them from there and avoid these calculations\n",
    "    \"\"\"\n",
    "    fmax_doa = np.min((fmax_doa, fs // 2))\n",
    "    n_bins = n_fft // 2 + 1\n",
    "    lower_bin = int(np.floor(fmin_doa * n_fft / float(fs)))\n",
    "    upper_bin = int(np.floor(fmax_doa * n_fft / float(fs)))\n",
    "    lower_bin = np.max((1, lower_bin))\n",
    "\n",
    "    # Cutoff frequency for spectrograms\n",
    "    fmax = 9000  # Hz, meant to reduce feature dimensions\n",
    "    cutoff_bin = int(np.floor(fmax * n_fft / float(fs)))  # 9000 Hz, 512 nfft: cutoff_bin = 192\n",
    "    assert upper_bin <= cutoff_bin, 'Upper bin for spatial feature is higher than cutoff bin for spectrogram!'\n",
    "\n",
    "    # Normalization factor for salsa_lite --> 2*pi*f/c\n",
    "    c = 343\n",
    "    delta = 2 * np.pi * fs / (n_fft * c)\n",
    "    freq_vector = np.arange(n_bins)\n",
    "    freq_vector[0] = 1\n",
    "    freq_vector = freq_vector[:, None, None]  # n_bins x 1 x 1\n",
    "    \n",
    "    # Extract the features from the audio data\n",
    "    \"\"\"\n",
    "    The audio data is from the ambimik, assuming that it is a four-channel array\n",
    "    The shape should be (4 , x) for (n_channels, time*fs)\n",
    "    \"\"\"\n",
    "    log_specs = []\n",
    "    for imic in np.arange(n_mics):\n",
    "        # audio_mic_data = local_scaling(audio_data[imic, :]) \n",
    "        audio_mic_data = audio_data[imic, :]\n",
    "        stft = librosa.stft(y=np.asfortranarray(audio_mic_data), \n",
    "                            n_fft=n_fft, \n",
    "                            hop_length=hop_length,\n",
    "                            center=True, \n",
    "                            window='hann', \n",
    "                            pad_mode='reflect')\n",
    "        if imic == 0:\n",
    "            n_frames = stft.shape[1]\n",
    "            X = np.zeros((n_bins, n_frames, n_mics), dtype='complex')  # (n_bins, n_frames, n_mics)\n",
    "        X[:, :, imic] = stft\n",
    "        # Compute log linear power spectrum\n",
    "        spec = (np.abs(stft) ** 2).T\n",
    "        log_spec = librosa.power_to_db(spec, ref=1.0, amin=1e-10, top_db=None)\n",
    "        log_spec = np.expand_dims(log_spec, axis=0)\n",
    "        log_specs.append(log_spec)\n",
    "    log_specs = np.concatenate(log_specs, axis=0)  # (n_mics, n_frames, n_bins)\n",
    "\n",
    "    # Compute spatial feature\n",
    "    # X : (n_bins, n_frames, n_mics) , NIPD formula : -(c / (2pi x f)) x arg[X1*(t,f) . X2:M(t,f)]\n",
    "    phase_vector = np.angle(X[:, :, 1:] * np.conj(X[:, :, 0, None]))\n",
    "    phase_vector = phase_vector / (delta * freq_vector)\n",
    "    phase_vector = np.transpose(phase_vector, (2, 1, 0))  # (n_mics, n_frames, n_bins)\n",
    "    \n",
    "    # Crop frequency\n",
    "    log_specs = log_specs[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector = phase_vector[:, :, lower_bin:cutoff_bin]\n",
    "    phase_vector[:, :, upper_bin:] = 0\n",
    "    \n",
    "    # Stack features\n",
    "    audio_feature = np.concatenate((log_specs, phase_vector), axis=0)\n",
    "    audio_feature = audio_feature.astype(np.float32)\n",
    "    \n",
    "    # Now we normalize the first 4 log power spectrogram channels of SALSALITE\n",
    "    n_feature_channels = 4\n",
    "    scaler_dict = {}\n",
    "    for i_chan in np.arange(n_feature_channels):\n",
    "        scaler_dict[i_chan] = preprocessing.StandardScaler()\n",
    "        scaler_dict[i_chan].partial_fit(audio_feature[i_chan, : , : ]) # (n_timesteps, n_features)\n",
    "        \n",
    "    # Extract mean and std\n",
    "    feature_mean = []\n",
    "    feature_std = []\n",
    "    for i_chan in range(n_feature_channels):\n",
    "        feature_mean.append(scaler_dict[i_chan].mean_)\n",
    "        feature_std.append(np.sqrt(scaler_dict[i_chan].var_))\n",
    "\n",
    "    feature_mean = np.array(feature_mean)\n",
    "    feature_std = np.array(feature_std)\n",
    "\n",
    "    # Expand dims for timesteps: (n_chanels, n_timesteps, n_features)\n",
    "    feature_mean = np.expand_dims(feature_mean, axis=1)\n",
    "    feature_std = np.expand_dims(feature_std, axis=1)\n",
    "    audio_feature[:4] = (audio_feature[:4] - feature_mean)/feature_std\n",
    "        \n",
    "    return audio_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_index():\n",
    "    return random.randint(0,4900)\n",
    "\n",
    "def get_random_numframes_replace():\n",
    "    return random.randint(0,7)\n",
    "\n",
    "def get_mask(i):\n",
    "    if i == 0:\n",
    "        return [True, False, False, False, False]\n",
    "    elif i == 1:\n",
    "        return [False, True, True, True, True]\n",
    "    elif i == 2:\n",
    "        return [False, False, True, True, True]\n",
    "    elif i == 3:\n",
    "        return [False, False, False, True, True]\n",
    "    elif i == 4:\n",
    "        return [False, False, False, False, True]\n",
    "    elif i == 5:\n",
    "        return [True, True, True, True, False]\n",
    "    elif i == 6:\n",
    "        return [True, True, True, False, False]\n",
    "    elif i == 7:\n",
    "        return [True, True, False, False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat all noise data together and form a pool of ambient sound data to populate our active sound data with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49118, 4, 4800)\n"
     ]
    }
   ],
   "source": [
    "fs = 48000\n",
    "concatenated_noise_track_fp = \"./data/Dataset_concatenated_tracks/Noise/noise_scaled_0.wav\"\n",
    "all_noise_data, _ = librosa.load(concatenated_noise_track_fp, sr=fs , mono=False, dtype=np.float32)\n",
    "\n",
    "samples_per_frame = int(fs * 0.1)\n",
    "all_noise_frames = [all_noise_data[: , i:i+samples_per_frame] for i in range(0, len(all_noise_data[0]), samples_per_frame)]\n",
    "all_noise_frames_array = np.array(all_noise_frames)\n",
    "\n",
    "print(all_noise_frames_array.shape)\n",
    "# (how many 100ms frame, 4 channels, sample points for 100ms frame (4800))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we augment each segmeneted audio data file at random with noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14352/14352 [19:39<00:00, 12.17it/s]\n",
      "100%|██████████| 16026/16026 [25:06<00:00, 10.64it/s]\n",
      "100%|██████████| 14424/14424 [24:05<00:00,  9.98it/s]\n"
     ]
    }
   ],
   "source": [
    "segmented_data_fp = \"./_audio/cleaned_data_0.5s_0.25s/\"\n",
    "active_classes_dir = ['dog', 'impact', 'speech']\n",
    "active_classes = ['dog', 'impact', 'speech', 'noise']\n",
    "fs = 48000\n",
    "samples_per_frame = int(fs * 0.1)\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for cls in active_classes_dir:\n",
    "    class_filepath = os.path.join(segmented_data_fp, cls)\n",
    "    for file in tqdm(os.listdir(class_filepath)):\n",
    "        if file.endswith('.wav'):\n",
    "            # Get the clean, segmented audio\n",
    "            audio_filepath = os.path.join(class_filepath, file)\n",
    "            audio_data, _ = librosa.load(audio_filepath, sr=fs, mono=False, dtype=np.float32)\n",
    "            \n",
    "            # Here, we get the mask to see which 100ms frames to keep/replace\n",
    "            replacement = get_mask(get_random_numframes_replace())\n",
    "            \n",
    "            # Converting the audio data into 100ms frames\n",
    "            feature_audio_frames = [audio_data[: , i:i+samples_per_frame] for i in range(0, len(audio_data[0]), samples_per_frame)]\n",
    "            \n",
    "            augmented_audio = []\n",
    "            \n",
    "            # Here we either keep the class audio, or we replace them with a random noise audio\n",
    "            for idx, keep in enumerate(replacement):\n",
    "                if keep:\n",
    "                    augmented_audio.append(feature_audio_frames[idx])\n",
    "                else:\n",
    "                    noiseframe_idx = get_random_index()\n",
    "                    augmented_audio.append(all_noise_frames_array[noiseframe_idx])\n",
    "                    \n",
    "            # Combine them all together \n",
    "            augmented_audio_array = np.array(augmented_audio)\n",
    "            augmented_audio_array = np.concatenate(augmented_audio_array, axis = -1)\n",
    "            \n",
    "            # Finally, we convert this augmented audio into features\n",
    "            salsalite_features = extract_features(augmented_audio_array)\n",
    "            \n",
    "            # filename --> class_azimuth_index.wav, get the ground truths\n",
    "            filename_gts = file.replace('.wav' , \"\")\n",
    "            gts = filename_gts.split(\"_\")\n",
    "            \n",
    "            # This is for active class ground truth (sed, doax, doay)\n",
    "            one_frame_gt = np.zeros(len(active_classes) * 3, dtype=np.float32)\n",
    "            class_index = active_classes.index(gts[0])\n",
    "            one_frame_gt[class_index] = 1\n",
    "            \n",
    "            # Converting Azimuth into radians and assigning to active class\n",
    "            gt_azi = int(gts[1])\n",
    "            # Convert the azimuth from [0, 360) to [-180, 180), taking (0 == 0) and (180 == -180)\n",
    "            if gt_azi == 330:\n",
    "                gt_azi = -30\n",
    "            elif gt_azi == 270:\n",
    "                gt_azi = -90\n",
    "            elif gt_azi == 210:\n",
    "                gt_azi = -150\n",
    "\n",
    "            azi_rad = gt_azi * np.pi / 180.0 # Convert to radian unit this way\n",
    "            one_frame_gt[class_index + len(active_classes)] = np.cos(azi_rad) # X-coordinate\n",
    "            one_frame_gt[class_index + 2 * len(active_classes)] = np.sin(azi_rad) # Y-coordinate\n",
    "            # Produce the ground truth labels for a single frame, expand the frame dimensions later\n",
    "            one_frame_gt = np.reshape(one_frame_gt, (1, len(one_frame_gt)))\n",
    "            \n",
    "            # This is for noise frame ground truth\n",
    "            noise_frame_gt = np.zeros(len(active_classes) * 3, dtype=np.float32)\n",
    "            noise_frame_gt = np.reshape(noise_frame_gt, (1, len(noise_frame_gt)))\n",
    "            \n",
    "            # Finally, we combine the active class and noise ground truths \n",
    "            gt_result = np.empty((5, len(active_classes)*3))\n",
    "            for is_kept in replacement:\n",
    "                if is_kept:\n",
    "                    gt_result = np.concatenate((gt_result, one_frame_gt), axis=0)\n",
    "                else:\n",
    "                    gt_result = np.concatenate((gt_result, noise_frame_gt), axis=0)\n",
    "            \n",
    "            all_features.append(salsalite_features)\n",
    "            all_labels.append(gt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset_storagepath = \"./training_datasets/demo_dataset_0.5s_0.25s_wgn20\"\n",
    "feature_fp = os.path.join(final_dataset_storagepath, \"augmented_salsalite_features.npy\")\n",
    "np.save(feature_fp, all_features, allow_pickle=True)\n",
    "\n",
    "label_fp = os.path.join(final_dataset_storagepath, \"augmented_salsalite_labels.npy\")\n",
    "np.save(label_fp, all_labels, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(os.path.join(final_dataset_storagepath, 'demo_salsalite_features.npy'), allow_pickle=True)\n",
    "b = np.load(os.path.join(final_dataset_storagepath, 'augmented_salsalite_features.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59142, 5, 12) (44802, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "x = np.load(os.path.join(final_dataset_storagepath, 'demo_gt_labels.npy'), allow_pickle=True)\n",
    "y = np.load(os.path.join(final_dataset_storagepath, 'augmented_salsalite_labels.npy'), allow_pickle=True)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y[:, 5:, :]\n",
    "np.save(os.path.join(final_dataset_storagepath, 'augmented_salsalite_labels.npy'), z, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 7.74405599e-01  9.75001872e-01  8.47373068e-01 ...  5.48904605e-18\n",
      "   -3.90573308e-19  1.55190808e-18]\n",
      "  [ 6.98455513e-01  9.63841140e-01  8.75459492e-01 ...  5.17265219e-03\n",
      "   -1.16827125e-02  5.24178194e-03]\n",
      "  [ 8.32469642e-01  9.79508698e-01  8.81196082e-01 ...  1.30391854e-03\n",
      "    4.52351896e-03 -3.53804417e-03]\n",
      "  ...\n",
      "  [-1.23735356e+00 -1.15147245e+00 -1.11265898e+00 ... -2.16396786e-02\n",
      "   -6.22365475e-02  1.21090999e-02]\n",
      "  [-8.22550058e-01 -9.21732664e-01 -9.40576851e-01 ...  2.45759655e-02\n",
      "   -5.56835793e-02  3.51610780e-02]\n",
      "  [ 1.08922482e+00  5.08546948e-01  3.55669826e-01 ... -7.52681299e-05\n",
      "    2.10309096e-04 -7.05647835e-05]]\n",
      "\n",
      " [[-3.23636413e+00 -2.37428212e+00 -9.84230578e-01 ... -2.75037104e-16\n",
      "    9.14666653e-01  9.14666653e-01]\n",
      "  [-2.25681710e+00  2.70174354e-01 -1.28524065e+00 ...  6.71516299e-01\n",
      "   -2.39355825e-02  5.27480900e-01]\n",
      "  [-7.38759995e-01 -9.59904194e-01 -1.76557863e+00 ...  4.19580400e-01\n",
      "   -6.88231945e-01 -4.31478947e-01]\n",
      "  ...\n",
      "  [-1.68735251e-01 -7.03215420e-01 -8.29991698e-01 ...  1.08774036e-01\n",
      "   -1.69509172e-01  3.08447033e-02]\n",
      "  [-2.49281359e+00 -8.22346032e-01 -6.74536884e-01 ... -3.17940086e-01\n",
      "   -2.13070676e-01 -2.96250880e-01]\n",
      "  [ 2.87724280e+00  2.72419143e+00  2.21516919e+00 ...  2.03127973e-04\n",
      "    7.93050494e-05  4.99456946e-05]]\n",
      "\n",
      " [[-3.08214188e+00 -1.69078279e+00  1.15584902e-01 ... -5.10162333e-16\n",
      "   -4.72759158e-16 -4.45471356e-16]\n",
      "  [-1.41975784e+00  2.86545038e-01 -7.38890707e-01 ... -3.62854898e-01\n",
      "    5.74665487e-01 -4.31558669e-01]\n",
      "  [ 1.66781992e-01 -8.13899100e-01 -1.39045513e+00 ...  5.67660093e-01\n",
      "   -6.32273629e-02 -6.41577318e-02]\n",
      "  ...\n",
      "  [ 1.75788474e+00  1.53633988e+00  1.39676344e+00 ...  2.24174373e-03\n",
      "   -7.47479722e-02  6.87754899e-03]\n",
      "  [-7.04742193e-01  8.90598118e-01  8.84044409e-01 ... -1.81406319e-01\n",
      "   -6.10669404e-02 -4.97988224e-01]\n",
      "  [ 3.15177441e+00  2.72656512e+00  2.24000812e+00 ... -2.92992452e-04\n",
      "   -7.91369530e-05 -2.82155997e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 6.32760108e-01  1.21894884e+00  4.12515938e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 8.16243470e-01  1.51915121e+00  1.04246807e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 1.54254699e+00  8.46563160e-01  7.37424254e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [-1.69043958e+00 -1.13692427e+00 -1.05675364e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-1.12444746e+00 -1.24497545e+00 -1.19210756e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-2.06219167e-01 -7.72288084e-01 -5.56586444e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.28948510e+00  1.86209369e+00  6.44583762e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 1.14568925e+00  2.75449157e-01  1.30294144e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 1.67216682e+00  1.46161616e+00  7.52062321e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [-1.23397791e+00 -1.13750052e+00 -1.00477779e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-1.38267589e+00 -2.37228489e+00 -8.50716531e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-4.56326604e-01 -6.98561311e-01 -4.35329169e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.61856139e+00  1.50552356e+00  8.76432002e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.98042536e-01  1.07529628e+00  1.11177123e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.62682414e-01  1.38459897e+00  1.08497131e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [-1.12428212e+00 -5.16323268e-01 -1.60939503e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-1.09709096e+00 -1.02871001e+00 -1.14038682e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-4.09449279e-01 -2.97454149e-01 -5.65681040e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 7.74405599e-01 -3.23636413e+00 -3.08214188e+00 ...  6.32760108e-01\n",
      "    1.28948510e+00  1.61856139e+00]\n",
      "  [ 6.98455513e-01 -2.25681710e+00 -1.41975784e+00 ...  8.16243470e-01\n",
      "    1.14568925e+00  7.98042536e-01]\n",
      "  [ 8.32469642e-01 -7.38759995e-01  1.66781992e-01 ...  1.54254699e+00\n",
      "    1.67216682e+00  6.62682414e-01]\n",
      "  ...\n",
      "  [-1.23735356e+00 -1.68735251e-01  1.75788474e+00 ... -1.69043958e+00\n",
      "   -1.23397791e+00 -1.12428212e+00]\n",
      "  [-8.22550058e-01 -2.49281359e+00 -7.04742193e-01 ... -1.12444746e+00\n",
      "   -1.38267589e+00 -1.09709096e+00]\n",
      "  [ 1.08922482e+00  2.87724280e+00  3.15177441e+00 ... -2.06219167e-01\n",
      "   -4.56326604e-01 -4.09449279e-01]]\n",
      "\n",
      " [[ 9.75001872e-01 -2.37428212e+00 -1.69078279e+00 ...  1.21894884e+00\n",
      "    1.86209369e+00  1.50552356e+00]\n",
      "  [ 9.63841140e-01  2.70174354e-01  2.86545038e-01 ...  1.51915121e+00\n",
      "    2.75449157e-01  1.07529628e+00]\n",
      "  [ 9.79508698e-01 -9.59904194e-01 -8.13899100e-01 ...  8.46563160e-01\n",
      "    1.46161616e+00  1.38459897e+00]\n",
      "  ...\n",
      "  [-1.15147245e+00 -7.03215420e-01  1.53633988e+00 ... -1.13692427e+00\n",
      "   -1.13750052e+00 -5.16323268e-01]\n",
      "  [-9.21732664e-01 -8.22346032e-01  8.90598118e-01 ... -1.24497545e+00\n",
      "   -2.37228489e+00 -1.02871001e+00]\n",
      "  [ 5.08546948e-01  2.72419143e+00  2.72656512e+00 ... -7.72288084e-01\n",
      "   -6.98561311e-01 -2.97454149e-01]]\n",
      "\n",
      " [[ 8.47373068e-01 -9.84230578e-01  1.15584902e-01 ...  4.12515938e-01\n",
      "    6.44583762e-01  8.76432002e-01]\n",
      "  [ 8.75459492e-01 -1.28524065e+00 -7.38890707e-01 ...  1.04246807e+00\n",
      "    1.30294144e+00  1.11177123e+00]\n",
      "  [ 8.81196082e-01 -1.76557863e+00 -1.39045513e+00 ...  7.37424254e-01\n",
      "    7.52062321e-01  1.08497131e+00]\n",
      "  ...\n",
      "  [-1.11265898e+00 -8.29991698e-01  1.39676344e+00 ... -1.05675364e+00\n",
      "   -1.00477779e+00 -1.60939503e+00]\n",
      "  [-9.40576851e-01 -6.74536884e-01  8.84044409e-01 ... -1.19210756e+00\n",
      "   -8.50716531e-01 -1.14038682e+00]\n",
      "  [ 3.55669826e-01  2.21516919e+00  2.24000812e+00 ... -5.56586444e-01\n",
      "   -4.35329169e-01 -5.65681040e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.48904605e-18 -2.75037104e-16 -5.10162333e-16 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 5.17265219e-03  6.71516299e-01 -3.62854898e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 1.30391854e-03  4.19580400e-01  5.67660093e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [-2.16396786e-02  1.08774036e-01  2.24174373e-03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 2.45759655e-02 -3.17940086e-01 -1.81406319e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-7.52681299e-05  2.03127973e-04 -2.92992452e-04 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[-3.90573308e-19  9.14666653e-01 -4.72759158e-16 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-1.16827125e-02 -2.39355825e-02  5.74665487e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 4.52351896e-03 -6.88231945e-01 -6.32273629e-02 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [-6.22365475e-02 -1.69509172e-01 -7.47479722e-02 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-5.56835793e-02 -2.13070676e-01 -6.10669404e-02 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 2.10309096e-04  7.93050494e-05 -7.91369530e-05 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 1.55190808e-18  9.14666653e-01 -4.45471356e-16 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 5.24178194e-03  5.27480900e-01 -4.31558669e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-3.53804417e-03 -4.31478947e-01 -6.41577318e-02 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 1.21090999e-02  3.08447033e-02  6.87754899e-03 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 3.51610780e-02 -2.96250880e-01 -4.97988224e-01 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [-7.05647835e-05  4.99456946e-05 -2.82155997e-05 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(b[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-lite-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
